{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525da13b-3d59-4545-8e27-69bb8388be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606fe88-3092-4d54-89b6-1394e7dc5aba",
   "metadata": {},
   "source": [
    "First, let get some utilities from brainiac_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1abdbf-07bc-4017-be9a-228b5d0d40e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fe85d6-6be6-49fe-a831-403f2d742238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota_paper_implementation.convertors.d2g22tgt import convert_d2g2_sample_to_tgt\n",
    "from brainiac_temporal.metrics.utility import link_forecasting_metric\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e82be0-d97c-4f18-bf5c-526340e4e5dc",
   "metadata": {},
   "source": [
    "Now, into D2G2 itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649a64b0-64d1-4def-af56-fe1967c9abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/sota_paper_implementation/D2G2\n"
     ]
    }
   ],
   "source": [
    "%cd sota_paper_implementation/D2G2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacff2de-1d3b-4d56-ac5d-1f2b0020af1c",
   "metadata": {},
   "source": [
    "## Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb150aa-7185-426f-a319-196fe242304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 39, 165, 165)\n",
      "(1, 39, 165, 1)\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"dataset/insecta/\")\n",
    "originals = convert_d2g2_sample_to_tgt(data_path, \"\")\n",
    "\n",
    "# --------- load data\n",
    "adj = np.load(data_path / Path(\"adj.npy\"), allow_pickle=True)\n",
    "features = np.load(data_path / Path(\"feature.npy\"), allow_pickle=True)\n",
    "\n",
    "# --------- after loading dataset\n",
    "# to torch\n",
    "adj = torch.from_numpy(adj).float()\n",
    "features = torch.from_numpy(features).float()\n",
    "dataset = torch.utils.data.TensorDataset(adj, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b9348-2c44-4e75-afe3-d17b5212c563",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff45ba4-65f3-490d-8417-28e0b8ee739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d57b9-e74d-4317-a72a-c15fab2b47cf",
   "metadata": {},
   "source": [
    "**You probably want to change 2 things:**\n",
    "\n",
    "`device = torch.device('cpu')` to cuda:0 if you have GPU access\n",
    "and\n",
    "`epochs=1` to a value that will actually train the model ;) Keep at 1 for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0611172b-4d8a-425b-9a3c-dd63829c359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0')\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43de414-c9e1-4c72-9ee9-e5a95013e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "z_dim = 32\n",
    "genr_batch_size = 100\n",
    "f_dim= 256\n",
    "\n",
    "seq_len = adj.size(1)\n",
    "max_num_nodes = adj.size(2)\n",
    "feature_dim = features.size(3)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "d2g2 = D2G2(\n",
    "    f_dim=f_dim,\n",
    "    z_dim=z_dim,\n",
    "    batch_size=batch_size,\n",
    "    seq_len=seq_len,\n",
    "    factorised=True,\n",
    "    device=device,\n",
    "    graphs=seq_len,\n",
    "    feature_dim=feature_dim,\n",
    "    max_num_nodes=max_num_nodes,\n",
    ")\n",
    "\n",
    "fix_f = torch.rand(f_dim, device=device)\n",
    "fix_f = fix_f.expand(genr_batch_size, seq_len, f_dim)\n",
    "test_f = fix_f\n",
    "\n",
    "trainer = Trainer(\n",
    "    d2g2,\n",
    "    loader,\n",
    "    test_f,\n",
    "    epochs=epochs,\n",
    "    learning_rate=0.0002,\n",
    "    device=device,\n",
    "    max_num_nodes=max_num_nodes,\n",
    "    genr_batch_size=genr_batch_size,\n",
    "    original_full_adj=adj,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c567164-0cb2-4f7d-b712-35831ae92ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Average Loss: 183957094400.0 Edge Loss 6.967780590057373 Node Loss 76105310208.0 KL of f : 88.32738494873047 KL of z : 107851792384.0 Bursty_Coeff: 0.0 Temporal_Efficiency: 0.0 Degree_Centrality 0.0 original_edges_total 78.0 recon_edges_total 534501.0\n",
      "Training is complete\n",
      "from sample_frames: edge and node:  torch.Size([100, 39, 32]) torch.Size([100, 39, 32])\n",
      "from sample_frames: test_f_expand.shape:  torch.Size([100, 39, 256])\n",
      "torch.Size([100, 39, 320]) torch.Size([100, 39, 320])\n",
      "from sample_frames: recon.shape:  torch.Size([100, 39, 165, 165]) torch.Size([100, 39, 165, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "trainer.train_model()\n",
    "trainer.sample_graphs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b20f38-81ec-4ba0-b193-f2b4e41aa935",
   "metadata": {},
   "source": [
    "You samples are now available in the output directory!\n",
    "\n",
    "D2G2 has hardcoded the sample path to `output/adj_metro_fix_z.npy` `output/feature_metro_fix_z.npy`.\n",
    "\n",
    "we recommand moving it, to avoid it being overridden at the next run.\n",
    "\n",
    "They can be converted to the torch geometric temporal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4000db2-0b43-43cd-90ee-e98a6f82b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 39, 165, 165)\n",
      "(100, 39, 165, 1)\n"
     ]
    }
   ],
   "source": [
    "samples = convert_d2g2_sample_to_tgt(\"output/\", \"_metro_fix_z\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
