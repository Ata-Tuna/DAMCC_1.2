{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525da13b-3d59-4545-8e27-69bb8388be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1abdbf-07bc-4017-be9a-228b5d0d40e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valentin.lemaire/brainiac-1-temporal\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fe85d6-6be6-49fe-a831-403f2d742238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota_paper_implementation.convertors.d2g22tgt import convert_d2g2_sample_to_tgt\n",
    "from brainiac_temporal.metrics.utility import link_forecasting_metric\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649a64b0-64d1-4def-af56-fe1967c9abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valentin.lemaire/brainiac-1-temporal/sota_paper_implementation/D2G2\n"
     ]
    }
   ],
   "source": [
    "%cd sota_paper_implementation/D2G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb150aa-7185-426f-a319-196fe242304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 39, 165, 165)\n",
      "(1, 39, 165, 1)\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"dataset/insecta/\")\n",
    "originals = convert_d2g2_sample_to_tgt(data_path, \"\")\n",
    "\n",
    "# --------- load data\n",
    "adj = np.load(data_path / Path(\"adj.npy\"), allow_pickle=True)\n",
    "features = np.load(data_path / Path(\"feature.npy\"), allow_pickle=True)\n",
    "\n",
    "# --------- after loading dataset\n",
    "# to torch\n",
    "adj = torch.from_numpy(adj).float()\n",
    "features = torch.from_numpy(features).float()\n",
    "dataset = torch.utils.data.TensorDataset(adj, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff45ba4-65f3-490d-8417-28e0b8ee739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from trainer import *\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d57b9-e74d-4317-a72a-c15fab2b47cf",
   "metadata": {},
   "source": [
    "**You probably want to change 2 things:**\n",
    "\n",
    "`device = torch.device('cpu')`\n",
    "and\n",
    "`epochs=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43de414-c9e1-4c72-9ee9-e5a95013e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 8\n",
    "# z_dim = 32\n",
    "# genr_batch_size = 100\n",
    "# f_dim= 256\n",
    "\n",
    "from brainiac_temporal.metrics import MetricEvaluator\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 16, step=8)\n",
    "    z_dim = trial.suggest_int(\"z_dim\", 8, 64, step=8)\n",
    "    genr_batch_size = trial.suggest_int(\"genr_batch_size\", 100, 120, step=10)\n",
    "    f_dim = trial.suggest_int(\"f_dim\", 128, 512, step=64)\n",
    "\n",
    "    seq_len = adj.size(1)\n",
    "    max_num_nodes = adj.size(2)\n",
    "    feature_dim = features.size(3)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    "    )\n",
    "    # device = torch.device('cuda:0')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    d2g2 = D2G2(\n",
    "        f_dim=f_dim,\n",
    "        z_dim=z_dim,\n",
    "        batch_size=batch_size,\n",
    "        seq_len=seq_len,\n",
    "        factorised=True,\n",
    "        device=device,\n",
    "        graphs=seq_len,\n",
    "        feature_dim=feature_dim,\n",
    "        max_num_nodes=max_num_nodes,\n",
    "    )\n",
    "\n",
    "    fix_f = torch.rand(f_dim, device=device)\n",
    "    fix_f = fix_f.expand(genr_batch_size, seq_len, f_dim)\n",
    "    test_f = fix_f\n",
    "\n",
    "    trainer = Trainer(\n",
    "        d2g2,\n",
    "        loader,\n",
    "        test_f,\n",
    "        epochs=1,\n",
    "        learning_rate=0.0002,\n",
    "        device=device,\n",
    "        max_num_nodes=max_num_nodes,\n",
    "        genr_batch_size=genr_batch_size,\n",
    "        original_full_adj=adj,\n",
    "    )\n",
    "\n",
    "    trainer.train_model()\n",
    "    trainer.sample_graphs()\n",
    "\n",
    "    samples = convert_d2g2_sample_to_tgt(\"output/\")\n",
    "\n",
    "    evaluator = MetricEvaluator(\n",
    "        statistics=[\"degree\"],\n",
    "        utility_metrics=None,\n",
    "        temporal_metrics=None,\n",
    "    )\n",
    "\n",
    "    results = evaluator(samples, originals)\n",
    "    score = results[\"degree\"]\n",
    "    # score = link_forecasting_metric(samples, originals, max_epochs=10)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c12bcf8-8f85-4f20-bc2b-9d1e3b510e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-21 14:30:48,516] A new study created in memory with name: no-name-87f518eb-98a8-4753-a266-53bd9f129793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Average Loss: 82525.59375 Edge Loss 1.3831706047058105 Node Loss 48882.38671875 KL of f : 72.19434356689453 KL of z : 33569.6328125 Bursty_Coeff: 0.0 Temporal_Efficiency: 0.0 Degree_Centrality 0.0 original_edges_total 78.0 recon_edges_total 529541.0\n",
      "Training is complete\n",
      "from sample_frames: edge and node:  torch.Size([120, 39, 40]) torch.Size([120, 39, 40])\n",
      "from sample_frames: test_f_expand.shape:  torch.Size([120, 39, 448])\n",
      "torch.Size([120, 39, 528]) torch.Size([120, 39, 528])\n",
      "from sample_frames: recon.shape:  torch.Size([120, 39, 165, 165]) torch.Size([120, 39, 165, 1])\n",
      "(120, 39, 165, 165)\n",
      "(120, 39, 165, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-21 14:31:18,150] Trial 0 finished with value: 171.21349975980283 and parameters: {'batch_size': 16, 'z_dim': 40, 'genr_batch_size': 120, 'f_dim': 448}. Best is trial 0 with value: 171.21349975980283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree\n",
      "Running Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Average Loss: 157697.5625 Edge Loss 1.379209041595459 Node Loss 74354.3125 KL of f : 55.547935485839844 KL of z : 83286.3203125 Bursty_Coeff: 0.0 Temporal_Efficiency: 0.0 Degree_Centrality 0.0 original_edges_total 78.0 recon_edges_total 534868.0\n",
      "Training is complete\n",
      "from sample_frames: edge and node:  torch.Size([100, 39, 32]) torch.Size([100, 39, 32])\n",
      "from sample_frames: test_f_expand.shape:  torch.Size([100, 39, 384])\n",
      "torch.Size([100, 39, 448]) torch.Size([100, 39, 448])\n",
      "from sample_frames: recon.shape:  torch.Size([100, 39, 165, 165]) torch.Size([100, 39, 165, 1])\n",
      "(100, 39, 165, 165)\n",
      "(100, 39, 165, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-21 14:31:42,714] Trial 1 finished with value: 176.58903561659767 and parameters: {'batch_size': 16, 'z_dim': 32, 'genr_batch_size': 100, 'f_dim': 384}. Best is trial 0 with value: 171.21349975980283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0885c5-5db2-4c8c-9666-72616d97e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(data_path / Path(\"best_params.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8cf0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
