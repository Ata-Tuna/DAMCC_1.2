{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal NNDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook show how to step by step get the temporal NNDR \n",
    "\n",
    "- Loading a checkpoint of an embedder trained on original dataset.\n",
    "- Getting temporal embedding from original and generated sets.\n",
    "- Applying DTW to calculate a distance matrix between these embeddings.\n",
    "- Applying NNDR on this matrix to assess privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/houssem.souid/brainiac-1-temporal\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.data.datasets import (\n",
    "    fetch_insecta_dataset,\n",
    "    load_imdb_dynamic_tgt,\n",
    "    load_tigger_datasets_tgt,\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import torch_geometric_temporal as tgt  # type: ignore\n",
    "from brainiac_temporal.data import LightningTemporalDataset\n",
    "from brainiac_temporal.models import LinkPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the dataset and the corresponding embedder checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name= \"wiki_small\"\n",
    "\n",
    "reference_dataset = load_tigger_datasets_tgt(dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota_paper_implementation.convertors.dymond2tgt import convert_dymond_sample_to_tgt\n",
    "\n",
    "# Load generated graph, works if you are on Tartarus\n",
    "path = \"/home/houssem.souid/brainiac-1-temporal/generated_graphs/dymond/generated_graph.pklz\"\n",
    "syn_data= convert_dymond_sample_to_tgt(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset.snapshot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data.snapshot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1616, 1], edge_index=[2, 48], edge_attr=[48], y=[1616])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1616, 1], edge_index=[2, 2], edge_attr=[2], y=[1616])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = reference_dataset.features[0].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the corresponding embedder from the checkpoints folder available on tartars:\n",
    "\n",
    "- /home/houssem.souid/brainiac1_temporal/checkpoints_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "checkpoint = torch.load(\"/home/houssem.souid/brainiac-1-temporal/checkpoints_lp/best_wiki_small.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = LinkPredictor(\n",
    "                node_features=node_features,\n",
    "                embedding_size=checkpoint[\"embedding_size\"],\n",
    "                mlp_hidden_sizes= checkpoint[\"mlp_hidden_sizes\"],\n",
    "                message_passing_class=\"GConvGRU\",\n",
    "                message_passing_kwargs= checkpoint[\"message_passing_kwargs\"]\n",
    "            \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer weights from the checkpoint to the model\n",
    "embedder.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkPredictor(\n",
       "  (recurrent): GConvGRU(\n",
       "    (conv_x_z): ChebConv(1, 32, K=2, normalization=sym)\n",
       "    (conv_h_z): ChebConv(32, 32, K=2, normalization=sym)\n",
       "    (conv_x_r): ChebConv(1, 32, K=2, normalization=sym)\n",
       "    (conv_h_r): ChebConv(32, 32, K=2, normalization=sym)\n",
       "    (conv_x_h): ChebConv(1, 32, K=2, normalization=sym)\n",
       "    (conv_h_h): ChebConv(32, 32, K=2, normalization=sym)\n",
       "  )\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (auc): BinaryAUROC()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embeddings on both original and generated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, data: Data, prev_embedding = None):\n",
    "    with torch.no_grad():\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Apply the model to get embeddings\n",
    "        embeddings = model(x, edge_index, prev_embedding)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1854069/2179758065.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = get_embeddings(embedder, data, torch.tensor(embeddings))\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataset and compute embeddings\n",
    "\n",
    "embeddings =  get_embeddings(embedder, reference_dataset[0])\n",
    "orig_embeddings_list= [embeddings.cpu().numpy()]\n",
    "for data in reference_dataset[1:]:\n",
    "    embeddings = get_embeddings(embedder, data, torch.tensor(embeddings))\n",
    "    orig_embeddings_list.append(embeddings.cpu().numpy())\n",
    "\n",
    "\n",
    "orig_embeddings = np.stack(orig_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1854069/1116597166.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings = get_embeddings(embedder, data, torch.tensor(embeddings))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate through your dataset and compute embeddings\n",
    "embeddings =  get_embeddings(embedder, syn_data[0])\n",
    "gen_embeddings_list= [embeddings.cpu().numpy()]\n",
    "for data in syn_data[1:]:\n",
    "    if data.edge_index.size(0) != 0:\n",
    "        embeddings = get_embeddings(embedder, data, torch.tensor(embeddings))\n",
    "    gen_embeddings_list.append(embeddings.cpu().numpy())\n",
    "\n",
    "gen_embeddings = np.stack(gen_embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1616, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1616, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "orig_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply dtw on temporal embeddings to obtain the embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtaidistance.dtw_ndim import distance_fast\n",
    "#distance_fast requires conversion to double\n",
    "gen_embeddings = np.array(gen_embeddings, dtype=np.float64)\n",
    "orig_embeddings = np.array(orig_embeddings, dtype=np.float64)\n",
    "#get matrix of embeddings\n",
    "emb_matrix = [\n",
    "   [distance_fast(gen_embeddings[:, i, :], orig_embeddings[:, j, :]) \n",
    "   for j in range(orig_embeddings.shape[1])]\n",
    "   for i in range(gen_embeddings.shape[1])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the NNDR score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.metrics.nndr import get_nndr\n",
    "(nndr_sore, hist, edges) = get_nndr(torch.Tensor(emb_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndr_sore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1584.,    0.,    0.,  ...,   30.,    0., 1584.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 3.1736e-09, 6.3471e-09,  ..., 2.4406e-07, 2.4644e-07,\n",
       "        2.4882e-07])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using integrated nndr in brainiac_temporal evaluator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.metrics.evaluator import MetricEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluator = MetricEvaluator(utility_metrics = None,get_privacy_metric=True, embedder_path= \"/home/houssem.souid/brainiac-1-temporal/checkpoints_lp/best_wiki_small.ckpt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'networkx.utils.decorators.argmap'> compilation 4:4: FutureWarning: normalized_laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral\n",
      "degree\n",
      "degree_centrality\n",
      "clustering\n",
      "closeness_centrality\n",
      "katz_centrality\n",
      "eigenvector_centrality\n",
      "avg_clust_coeff\n",
      "transitivity\n",
      "diameter\n",
      "average_shortest_path_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houssem.souid/brainiac-1-temporal/src/brainiac_temporal/metrics/nndr/utils.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embedder, data, torch.tensor(embeddings)\n"
     ]
    }
   ],
   "source": [
    "metrics = metric_evaluator(reference_dataset, syn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metrics[\"nndr_score\"] == nndr_sore.cpu().numpy()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metrics[\"nndr_histogram\"] == hist.cpu().numpy()).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metrics[\"nndr_edges\"]== edges.cpu().numpy()).any()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
