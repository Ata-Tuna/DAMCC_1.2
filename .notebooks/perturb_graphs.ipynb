{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/houssem.souid/brainiac-1-temporal\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.data.peturb_topology import perturb_tgt_graph_topology\n",
    "from brainiac_temporal.data.datasets import fetch_insecta_dataset\n",
    "from brainiac_temporal.data.utils import remove_isolated_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name= \"insecta\"\n",
    "\n",
    "dynamic_signal =fetch_insecta_dataset(colony=6)\n",
    "reference_dataset = remove_isolated_nodes(dynamic_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation on topology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturb dataset with multiple ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pertubed_graph = perturb_tgt_graph_topology(reference_dataset, [0.001, 0.01, 0.1, 0.5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's loop over the perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_1 = pertubed_graph[0.001]\n",
    "g_2 = pertubed_graph[0.01]\n",
    "g_3 = pertubed_graph[0.1]\n",
    "g_4 = pertubed_graph[0.5]\n",
    "g_5 = pertubed_graph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 137, 138, 138],\n",
       "        [  1,   2,   3,  ..., 136, 136, 137]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   7,  ..., 163, 163, 163],\n",
       "        [ 63,  59,   8,  ..., 135, 136, 138]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 163, 163, 163],\n",
       "        [  3,   4,   6,  ..., 158, 161, 162]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_4[0].edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the pertubed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.metrics import MetricEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MetricEvaluator(\n",
    "            statistics=\"all\",\n",
    "            temporal_aggregation=\"dtw\",\n",
    "            utility_metrics=None,\n",
    "            temporal_metrics=\"auto\",\n",
    "            get_privacy_metric=True,\n",
    "            embedder_path=\"checkpoints_lp_rm_isolated_nodes/best_insecta.ckpt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral\n",
      "degree\n",
      "degree_centrality\n",
      "clustering\n",
      "closeness_centrality\n",
      "katz_centrality\n",
      "eigenvector_centrality\n",
      "avg_clust_coeff\n",
      "transitivity\n",
      "diameter\n",
      "average_shortest_path_length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houssem.souid/brainiac-1-temporal/src/brainiac_temporal/metrics/nndr/utils.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embedder, data, torch.tensor(embeddings)\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluator(\n",
    "            original=reference_dataset,\n",
    "            generated=g_1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spectral': 0.010284821238619344,\n",
       " 'degree': 3.4550687402713134,\n",
       " 'degree_centrality': 4.937104414532874,\n",
       " 'clustering': 0.006348129664761474,\n",
       " 'closeness_centrality': 0.03206631179037227,\n",
       " 'katz_centrality': nan,\n",
       " 'eigenvector_centrality': 0.0029131697921128234,\n",
       " 'avg_clust_coeff': 0.025759079213563883,\n",
       " 'transitivity': 0.001647932727574813,\n",
       " 'diameter': 2.0,\n",
       " 'average_shortest_path_length': 0.25958345845120306,\n",
       " 'temporal_correlation': 9.99893701521031,\n",
       " 'diff_avg_temporal_closeness': 0.0006775067751050301,\n",
       " 'diff_avg_temporal_clustering_coefficient': 0.0006398292804118411,\n",
       " 'NNDR_mean': 0.25600001215934753,\n",
       " 'NNDR_std': 0.2980000078678131}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral\n",
      "degree\n",
      "degree_centrality\n",
      "clustering\n",
      "closeness_centrality\n",
      "katz_centrality\n",
      "eigenvector_centrality\n",
      "avg_clust_coeff\n",
      "transitivity\n",
      "diameter\n",
      "average_shortest_path_length\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluator(\n",
    "            original=reference_dataset,\n",
    "            generated=g_4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spectral': 3.8742660065616397,\n",
       " 'degree': 169.72551369785273,\n",
       " 'degree_centrality': 4.937104414532874,\n",
       " 'clustering': 1.466629834402638,\n",
       " 'closeness_centrality': 2.270710218161507,\n",
       " 'katz_centrality': nan,\n",
       " 'eigenvector_centrality': 0.11379823069802994,\n",
       " 'avg_clust_coeff': 0.2634596200694959,\n",
       " 'transitivity': 0.39694868593126437,\n",
       " 'diameter': 0.0,\n",
       " 'average_shortest_path_length': 1.083854888326082,\n",
       " 'temporal_correlation': 9.789819609085814,\n",
       " 'diff_avg_temporal_closeness': 2.0548780487804947,\n",
       " 'diff_avg_temporal_clustering_coefficient': 0.35075712641797485,\n",
       " 'NNDR_mean': 0.9200000166893005,\n",
       " 'NNDR_std': 0.06400000303983688}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturb Featured dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainiac_temporal.data.utils import remove_isolated_nodes, perturb_featured_dataset\n",
    "import torch_geometric_temporal as tgt\n",
    "\n",
    "dataset_name= \"TwitterTennis\"\n",
    "dynamic_signal =tgt.TwitterTennisDatasetLoader().get_dataset()\n",
    "reference_dataset = remove_isolated_nodes(dynamic_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise the perturbation ratios\n",
    "perturbation_ratio =[0.05, 0.1, 0.25, 0.5,0.75, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features and topology follow the same amount of noise in this example\n",
    "pertubed_graphs ={}\n",
    "for p in perturbation_ratio:\n",
    "    pertubed_graphs[p] = perturb_featured_dataset(reference_dataset, features_perturbation_ratio =p, is_binary=False,noise_scale=0.1, topology_perturbation_ratio =[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[995, 16], edge_index=[2, 89], edge_attr=[89], y=[995])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[995, 16], edge_index=[2, 111], edge_attr=[111], y=[995])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pertubed_graphs[0.9][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical metrics as features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from brainiac_temporal.metrics.statistics.statistics import GraphStatistics\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name= \"TwitterTennis_node_degree_spectral_clustering\"\n",
    "dynamic_signal =tgt.TwitterTennisDatasetLoader().get_dataset()\n",
    "dynamic_signal = remove_isolated_nodes(dynamic_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = GraphStatistics(metrics=[\"degree\", \"spectral\", \"clustering\"], to_tensors=False)\n",
    "evaluator = GraphStatistics(metrics=[\"degree\", \"spectral\", \"clustering\"], to_tensors=False)\n",
    "metrics = evaluator(dynamic_signal)\n",
    "spectral = np.array([np.split(array, len(array)) for array in metrics[\"spectral\"]])\n",
    "degree = np.array([np.split(array, len(array)) for array in metrics[\"degree\"]])\n",
    "clustering = np.array([np.split(array, len(array)) for array in metrics[\"clustering\"]])\n",
    "feature_vector = np.concatenate((spectral, degree, clustering), axis=2)\n",
    "\n",
    "\n",
    "reference_dataset = DynamicGraphTemporalSignal(\n",
    "        edge_indices=dynamic_signal.edge_indices,\n",
    "        edge_weights=dynamic_signal.edge_weights,\n",
    "        features=feature_vector,\n",
    "        targets=dynamic_signal.targets,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_ratio =[0.05, 0.1, 0.25, 0.5,0.75, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pertubed_graphs ={}\n",
    "for p in perturbation_ratio:\n",
    "    pertubed_graphs[p] = perturb_featured_dataset(reference_dataset, features_perturbation_ratio =p, is_binary=False,topology_perturbation_ratio =[p])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate NNDR score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/houssem.souid/brainiac-1-temporal/src/brainiac_temporal/metrics/nndr/utils.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embedder, data, torch.tensor(embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated for 5.0\n"
     ]
    }
   ],
   "source": [
    "method=\"dtw\"\n",
    "evaluator = MetricEvaluator(\n",
    "            statistics=\"all\",\n",
    "            temporal_aggregation=\"dtw\",\n",
    "            utility_metrics=None,\n",
    "            temporal_metrics=\"auto\",\n",
    "            get_privacy_metric=True,\n",
    "            embedder_path= \"checkpoints_lp_rm_isolated_nodes/best_\" + dataset_name + \".ckpt\",\n",
    "            nndr_calculation_method= method\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "evaluation_results = {}\n",
    "privacy_score = evaluator._compute_nndr(\n",
    "            original=remove_isolated_nodes(reference_dataset),\n",
    "            generated=remove_isolated_nodes(reference_dataset),\n",
    "        )\n",
    "nndr={}\n",
    "nndr[\"NNDR_mean\"] = float( np.round(np.mean(privacy_score[\"nndr_score\"]),3))\n",
    "nndr[\"NNDR_std\"] =  float(np.round(np.std(privacy_score[\"nndr_score\"]),3))\n",
    "evaluation_results[\"0 %\"] = nndr\n",
    "# Iterate over perturbed graphs\n",
    "for perturbation_percentage, perturbed_graph in pertubed_graphs.items():\n",
    "    # Assuming you have a function `evaluate_graph` to evaluate each perturbed graph\n",
    "    privacy_score = evaluator._compute_nndr(\n",
    "            original=remove_isolated_nodes(reference_dataset),\n",
    "            generated=remove_isolated_nodes(perturbed_graph),\n",
    "        )\n",
    "    nndr={}\n",
    "    nndr[\"NNDR_mean\"] = float( np.round(np.mean(privacy_score[\"nndr_score\"]),3))\n",
    "    nndr[\"NNDR_std\"] =  float(np.round(np.std(privacy_score[\"nndr_score\"]),3))\n",
    "    \n",
    "\n",
    "    # Store the results in the evaluation dictionary\n",
    "    evaluation_results[str(perturbation_percentage *100) + \" %\"] = nndr\n",
    "    print(f\"Calculated for {str(perturbation_percentage *100)}\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_results = pd.DataFrame.from_dict(evaluation_results, orient='index')\n",
    "df_results.index.name = 'Perturbation Percentage'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_results.to_csv(\"/nndr_results/nndr_results_\"+ dataset_name + \"_\" + method +\".csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainiac-1-temporal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
